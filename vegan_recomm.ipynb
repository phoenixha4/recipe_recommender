{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phoenixha4/recipe_recommender/blob/main/vegan_recomm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeZwVE8wwxlU",
        "outputId": "da76c77a-a28e-4ab2-be0c-9c8b24a9e585"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   user_id                         likes           past_searches\n",
            "0        1                        [1021]              [582, 167]\n",
            "1        2    [1132, 890, 406, 803, 517]             [1026, 688]\n",
            "2        3                        [1246]                   [948]\n",
            "3        4        [1225, 281, 570, 1222]        [279, 285, 1233]\n",
            "4        5               [502, 414, 811]  [506, 1141, 787, 1306]\n",
            "5        6        [1160, 442, 1052, 443]   [108, 391, 905, 1058]\n",
            "6        7  [669, 1323, 542, 1162, 1332]        [497, 305, 1098]\n",
            "7        8    [1220, 657, 137, 513, 684]  [127, 1168, 1013, 354]\n",
            "8        9  [1233, 1165, 609, 675, 1292]          [239, 186, 46]\n",
            "9       10             [1317, 190, 1250]        [297, 889, 1179]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the vegan recipes dataset\n",
        "recipes_df = pd.read_csv('vegan_recipes.csv')\n",
        "\n",
        "# Generate synthetic user data\n",
        "num_users = 100  # Adjust the number of users as needed\n",
        "user_ids = range(1, num_users + 1)\n",
        "user_data = []\n",
        "\n",
        "for user_id in user_ids:\n",
        "    # Randomly select liked recipes (up to 5)\n",
        "    num_likes = np.random.randint(1, 6)\n",
        "    liked_recipes = np.random.choice(recipes_df['sno'], size=num_likes, replace=False)\n",
        "\n",
        "    # Randomly select past searches (up to 5)\n",
        "    num_searches = np.random.randint(1, 6)\n",
        "    past_searches = np.random.choice(recipes_df['sno'], size=num_searches, replace=False)\n",
        "\n",
        "    user_data.append({\n",
        "        'user_id': user_id,\n",
        "        'likes': liked_recipes,\n",
        "        'past_searches': past_searches\n",
        "    })\n",
        "\n",
        "# Create a DataFrame from the synthetic user data\n",
        "user_profiles_df = pd.DataFrame(user_data)\n",
        "\n",
        "# Display the user profiles\n",
        "print(user_profiles_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEwva1wKt9YT",
        "outputId": "f035347e-35f2-4b6e-b148-3bbdbc7c184e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from google.colab import files\n",
        "\n",
        "# Install necessary libraries\n",
        "!pip install pandas scikit-learn nltk\n",
        "\n",
        "# Download NLTK punkt and wordnet resources\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Download NLTK stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Function to clean ingredient text\n",
        "def clean_ingredient(ingredient):\n",
        "    # Remove quantities and measurements\n",
        "    ingredient = re.sub(r'\\b\\d+\\s*(tsp|tbsp|g|kg|oz|ml|cup|cups|grams|pounds)\\b', '', ingredient, flags=re.IGNORECASE)\n",
        "    # Remove common words\n",
        "    common_words = ['ingredient', 'optional', 'vegan', 'non-dairy', 'free', 'gluten-free', 'organic']\n",
        "    for word in common_words:\n",
        "        ingredient = ingredient.replace(word, '')\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    # Remove numbers and words indicating quantities\n",
        "    ingredient = ' '.join([word for word in ingredient.split() if not word.isdigit() and word.lower() not in stop_words])\n",
        "    return ingredient.strip()\n",
        "\n",
        "# Function to preprocess ingredients\n",
        "def preprocess_ingredients(ingredients):\n",
        "    tokens = nltk.word_tokenize(ingredients.lower())\n",
        "    cleaned_ingredients = [clean_ingredient(word) for word in tokens]\n",
        "    processed_text = ' '.join([lemmatizer.lemmatize(word) for word in cleaned_ingredients])\n",
        "    return processed_text\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"vegan_recipes.csv\")\n",
        "\n",
        "# Tokenization and Lemmatization using NLTK\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Apply preprocessing to the ingredients column\n",
        "df['processed_ingredients'] = df['ingredients'].apply(preprocess_ingredients)\n",
        "\n",
        "# Extract liked ingredients and past search ingredients for each user\n",
        "user_profiles_df['liked_ingredients'] = user_profiles_df['likes'].apply(lambda likes: df.loc[df['sno'].isin(likes), 'processed_ingredients'].tolist())\n",
        "user_profiles_df['searched_ingredients'] = user_profiles_df['past_searches'].apply(lambda searches: df.loc[df['sno'].isin(searches), 'processed_ingredients'].tolist())\n",
        "\n",
        "# Merge ingredients into a single list for each user\n",
        "user_profiles_df['all_ingredients'] = user_profiles_df.apply(lambda row: row['liked_ingredients'] + row['searched_ingredients'], axis=1)\n",
        "\n",
        "# Combine ingredients and titles into a single text for each recipe\n",
        "df['processed_text'] = df['processed_ingredients'] + ' ' + df['title']\n",
        "\n",
        "# Create a TF-IDF Vectorizer with normalization\n",
        "vectorizer = make_pipeline(TfidfVectorizer(stop_words='english'), Normalizer())\n",
        "\n",
        "# Transform the processed text column into TF-IDF features\n",
        "tfidf_matrix = vectorizer.fit_transform(df['processed_text'])\n",
        "\n",
        "# Compute the cosine similarity between recipes based on ingredients and titles\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Function to get recommendations based on ingredients\n",
        "def get_ingredient_recommendations(user_input_ingredients, num_recommendations=5):\n",
        "    # Preprocess user input ingredients\n",
        "    processed_user_ingredients = preprocess_ingredients(user_input_ingredients)\n",
        "\n",
        "    # Transform user input ingredients into TF-IDF features\n",
        "    user_tfidf = vectorizer.transform([processed_user_ingredients])\n",
        "\n",
        "    # Calculate cosine similarities between user input and all recipes\n",
        "    user_cosine_similarities = linear_kernel(user_tfidf, tfidf_matrix).flatten()\n",
        "\n",
        "    # Get indices of recipes sorted by similarity\n",
        "    recipe_indices = user_cosine_similarities.argsort()[::-1]\n",
        "\n",
        "    # Get the top N similar recipes\n",
        "    top_recipes = recipe_indices[1:num_recommendations + 1]\n",
        "\n",
        "\n",
        "\n",
        "    return df['title'].iloc[top_recipes]\n",
        "\n",
        "# Function to get user-specific recommendations based on ingredients and user preferences\n",
        "def get_user_and_ingredient_recommendations(user_input_ingredients, user_id, num_recommendations=5):\n",
        "    # Preprocess user input ingredients\n",
        "    processed_user_ingredients = preprocess_ingredients(user_input_ingredients)\n",
        "\n",
        "    # Transform user input ingredients into TF-IDF features\n",
        "    user_tfidf = vectorizer.transform([processed_user_ingredients])\n",
        "\n",
        "    # Calculate cosine similarities between user input and all recipes\n",
        "    user_cosine_similarities = linear_kernel(user_tfidf, tfidf_matrix).flatten()\n",
        "\n",
        "    # Combine cosine similarities based on user preferences and user input\n",
        "    combined_cosine_similarities = user_cosine_similarities + cosine_sim[user_id]\n",
        "\n",
        "    # Get indices of recipes sorted by combined similarity\n",
        "    recipe_indices = combined_cosine_similarities.argsort()[::-1]\n",
        "\n",
        "    # Get the top N similar recipes\n",
        "    top_recipes = recipe_indices[1:num_recommendations + 1]\n",
        "\n",
        "\n",
        "\n",
        "    return df['title'].iloc[top_recipes]\n",
        "\n",
        "# Function to get user-specific recommendations based on user preferences\n",
        "def get_user_recommendations(user_id, num_recommendations=5):\n",
        "    # Get indices of recipes sorted by user preferences\n",
        "    recipe_indices = cosine_sim[user_id].argsort()[::-1]\n",
        "\n",
        "    # Get the top N similar recipes\n",
        "    top_recipes = recipe_indices[1:num_recommendations + 1]\n",
        "\n",
        "\n",
        "\n",
        "    return df['title'].iloc[top_recipes]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC3-AiuWTQ-k",
        "outputId": "11e16269-6fb1-4804-a9f2-b7c0487b78c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   sno                                               href  \\\n",
            "0    0        https://veganuary.com/recipes/rainbow-rice/   \n",
            "1    1          https://veganuary.com/recipes/mfc-nachos/   \n",
            "2    2   https://veganuary.com/recipes/hazelnut-truffles/   \n",
            "3    3  https://veganuary.com/recipes/simple-roasted-r...   \n",
            "4    4  https://veganuary.com/recipes/baked-apple-char...   \n",
            "\n",
            "                            title  \\\n",
            "0                    Rainbow Rice   \n",
            "1                          Nachos   \n",
            "2               Hazelnut Truffles   \n",
            "3  Simple Roasted Radish by ChicP   \n",
            "4           Baked Apple Charlotte   \n",
            "\n",
            "                                         ingredients  \\\n",
            "0  Ingredients\\n\\nCarrot ribbons (just use a peel...   \n",
            "1  Ingredients\\n\\n400g Meatless Farm Co mince (or...   \n",
            "2  Ingredients\\n\\n100g hazelnuts\\n2 tablespoons +...   \n",
            "3  Ingredients\\n\\n1 170g tub beetroot and horsera...   \n",
            "4  Ingredients\\n\\n2 tbsp rapeseed oil\\n75g pitted...   \n",
            "\n",
            "                                         preparation  \\\n",
            "0  Method\\n\\nCook the rice as instructed on the p...   \n",
            "1  Preparation\\n\\nPreheat the oven to 350ºF\\nHeat...   \n",
            "2  Method\\n\\nPreheat the oven to 200c\\nPut the ha...   \n",
            "3  Preparation\\nPre heat the oven to 160°C\\nCut t...   \n",
            "4  Preparation\\n\\nServes 9\\nYou will need an 8inc...   \n",
            "\n",
            "                               processed_ingredients  \\\n",
            "0   carrot ribbon (  use  peeler  speed ) frozen ...   \n",
            "1    meatless farm co mince (  similar )    refri...   \n",
            "2    hazelnut  tablespoon +  tablespoon cacao  ta...   \n",
            "3     tub beetroot  horseradish houmous  mixed ra...   \n",
            "4    tbsp rapeseed oil  pitted date  bramley appl...   \n",
            "\n",
            "                                      processed_text  \n",
            "0   carrot ribbon (  use  peeler  speed ) frozen ...  \n",
            "1    meatless farm co mince (  similar )    refri...  \n",
            "2    hazelnut  tablespoon +  tablespoon cacao  ta...  \n",
            "3     tub beetroot  horseradish houmous  mixed ra...  \n",
            "4    tbsp rapeseed oil  pitted date  bramley appl...  \n"
          ]
        }
      ],
      "source": [
        "print(df.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR6-jWUsvjAI",
        "outputId": "5d1e1048-a18a-4d48-e70b-f837cfff8b7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Recipes recommended based on input ingredients:\n",
            "667                            Vegan Tofu Benedict\n",
            "61                   Baked Buckwheat with Tomatoes\n",
            "1094                       SOUTHWEST TOFU SCRAMBLE\n",
            "1166    SPINACH AND ‘RICOTTA’ VEGAN STUFFED SHELLS\n",
            "595       Roast Butternut Squash and Spinach Salad\n",
            "Name: title, dtype: object\n",
            "\n",
            "Recipes recommended based on user preferences and input ingredients:\n",
            "23                     Lentil Bolognese\n",
            "446        Turkish Tofu & Spinach Börek\n",
            "626                 Cottage Pie Cobbler\n",
            "750           Roasted Aubergine Lasagne\n",
            "463    Tofu Scramble Breakfast Burritos\n",
            "Name: title, dtype: object\n",
            "\n",
            "Recipes recommended based on user preferences:\n",
            "23                                    Lentil Bolognese\n",
            "750                          Roasted Aubergine Lasagne\n",
            "814    Cheese on Toast (with Potato and Carrot Cheese)\n",
            "421                                Spaghetti Bolognese\n",
            "626                                Cottage Pie Cobbler\n",
            "Name: title, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Example 1: Get recommendations based on ingredients only\n",
        "user_input_ingredients = \"tofu, spinach, tomato, garlic\"\n",
        "ingredient_recommendations = get_ingredient_recommendations(user_input_ingredients)\n",
        "print(f\"\\nRecipes recommended based on input ingredients:\")\n",
        "print(ingredient_recommendations)\n",
        "\n",
        "# Example 2: Get user-specific recommendations based on ingredients and user preferences\n",
        "user_input_ingredients = \"tofu, spinach, tomato, garlic\"\n",
        "user_id = 56\n",
        "user_and_ingredient_recommendations = get_user_and_ingredient_recommendations(user_input_ingredients, user_id)\n",
        "print(f\"\\nRecipes recommended based on user preferences and input ingredients:\")\n",
        "print(user_and_ingredient_recommendations)\n",
        "\n",
        "# Example 3: Get user-specific recommendations based on user preferences only\n",
        "user_id = 56\n",
        "user_recommendations = get_user_recommendations(user_id)\n",
        "print(f\"\\nRecipes recommended based on user preferences:\")\n",
        "print(user_recommendations)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOGjLscae5HUJMxltM104V/",
      "collapsed_sections": [
        "48D6tZ9IV7Ta"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
